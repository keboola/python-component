<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.1">
<title>keboola.component.interface API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>keboola.component.interface</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="keboola.component.interface.init_environment_variables"><code class="name flex">
<span>def <span class="ident">init_environment_variables</span></span>(<span>) ‑> <a title="keboola.component.dao.EnvironmentVariables" href="dao.html#keboola.component.dao.EnvironmentVariables">EnvironmentVariables</a></span>
</code></dt>
<dd>
<div class="desc"><p>Initializes environment variables available in the docker environment
<a href="https://developers.keboola.com/extend/common-interface/environment/#environment-variables">https://developers.keboola.com/extend/common-interface/environment/#environment-variables</a></p>
<h2 id="returns">Returns</h2>
<p>dao.EnvironmentVariables:</p></div>
</dd>
<dt id="keboola.component.interface.register_csv_dialect"><code class="name flex">
<span>def <span class="ident">register_csv_dialect</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Register the KBC CSV dialect</p></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="keboola.component.interface.CommonInterface"><code class="flex name class">
<span>class <span class="ident">CommonInterface</span></span>
<span>(</span><span>data_folder_path: str = None, log_level=20, logging_type=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A class handling standard tasks related to the
<a href="https://developers.keboola.com/extend/common-interface/">Keboola Common Interface</a>
e.g. config load, validation, component state, I/O handling, I/O metadata and manifest files.</p>
<p>It initializes the environment inject into the Docker container the KBC component runs in and abstracts the tasks
related to the Common Interface interaction.</p>
<h2 id="attributes">Attributes</h2>
<p>data_folder_path (str):
Full path to the /data folder
Initializes the CommonInterface environment. If the data_folder_path is not specified the folder
is established in following order:</p>
<ul>
<li>From provided argument if present: <code>-d</code> or <code>--data</code></li>
<li>From environment variable if present (KBC_DATADIR)</li>
<li>Defaults to /data/ if none of the above is specified</li>
</ul>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data_folder_path</code></strong> :&ensp;<code>str</code></dt>
<dd>path to a data folder.</dd>
<dt><strong><code>log_level</code></strong> :&ensp;<code>int</code></dt>
<dd>logging.INFO or logging.DEBUG</dd>
<dt><strong><code>logging_type</code></strong> :&ensp;<code>str</code></dt>
<dd>optional 'std' or 'gelf', if left empty determined automatically</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CommonInterface:
    &#34;&#34;&#34;
    A class handling standard tasks related to the
    [Keboola Common Interface](https://developers.keboola.com/extend/common-interface/)
    e.g. config load, validation, component state, I/O handling, I/O metadata and manifest files.

    It initializes the environment inject into the Docker container the KBC component runs in and abstracts the tasks
    related to the Common Interface interaction.

    Attributes:
        data_folder_path (str):
            Full path to the /data folder

    &#34;&#34;&#34;
    LOGGING_TYPE_STD = &#39;std&#39;
    LOGGING_TYPE_GELF = &#39;gelf&#39;

    def __init__(self, data_folder_path: str = None, log_level=logging.INFO, logging_type=None):
        &#34;&#34;&#34;
        Initializes the CommonInterface environment. If the data_folder_path is not specified the folder
        is established in following order:

        - From provided argument if present: `-d` or `--data`
        - From environment variable if present (KBC_DATADIR)
        - Defaults to /data/ if none of the above is specified

        Args:
            data_folder_path (str): path to a data folder.
            log_level (int): logging.INFO or logging.DEBUG
            logging_type (str): optional &#39;std&#39; or &#39;gelf&#39;, if left empty determined automatically
        &#34;&#34;&#34;
        self.environment_variables = init_environment_variables()
        register_csv_dialect()

        # init logging
        logging_type_inf = CommonInterface.LOGGING_TYPE_GELF if os.getenv(&#39;KBC_LOGGER_ADDR&#39;,
                                                                          None) else CommonInterface.LOGGING_TYPE_STD
        if not logging_type:
            logging_type = logging_type_inf

        if logging_type == CommonInterface.LOGGING_TYPE_STD:
            self.set_default_logger(log_level)
        elif logging_type == CommonInterface.LOGGING_TYPE_GELF:
            self.set_gelf_logger(log_level)

        # init data folder
        if not data_folder_path:
            data_folder_path = self._get_data_folder_from_context()

        # validate
        if not os.path.exists(data_folder_path) and not os.path.isdir(data_folder_path):
            raise ValueError(
                f&#34;The data directory does not exist, verify that the data directory is correct. Dir: &#34;
                f&#34;{data_folder_path}&#34;
            )

        self.data_folder_path = data_folder_path

    def _get_data_folder_from_context(self):
        # try to get from argument parameter

        # get from parameters
        argparser = argparse.ArgumentParser()
        argparser.add_argument(
            &#39;-d&#39;,
            &#39;--data&#39;,
            dest=&#39;data_dir&#39;,
            default=&#39;&#39;,
            help=&#39;Data directory&#39;
        )
        # unknown is to ignore extra arguments
        args, unknown = argparser.parse_known_args()
        data_folder_path = args.data_dir

        if data_folder_path == &#39;&#39; and self.environment_variables.data_dir:
            data_folder_path = self.environment_variables.data_dir
        elif data_folder_path == &#39;&#39;:
            data_folder_path = &#39;/data/&#39;

        return data_folder_path

    # ================================= Logging ==============================
    @staticmethod
    def set_default_logger(log_level: int = logging.INFO):  # noqa: E301
        &#34;&#34;&#34;
        Sets default console logger.

        Args:
            log_level: logging level, default: &#39;logging.INFO&#39;

        Returns:
            Logger object

        &#34;&#34;&#34;

        class InfoFilter(logging.Filter):
            def filter(self, rec):
                return rec.levelno in (logging.DEBUG, logging.INFO)

        hd1 = logging.StreamHandler(sys.stdout)
        hd1.addFilter(InfoFilter())
        hd2 = logging.StreamHandler(sys.stderr)
        hd2.setLevel(logging.WARNING)

        logging.getLogger().setLevel(log_level)
        # remove default handler
        for h in logging.getLogger().handlers:
            logging.getLogger().removeHandler(h)
        logging.getLogger().addHandler(hd1)
        logging.getLogger().addHandler(hd2)

        logger = logging.getLogger()
        return logger

    @staticmethod
    def set_gelf_logger(log_level: int = logging.INFO, transport_layer=&#39;TCP&#39;,
                        stdout=False, include_extra_fields=True, **gelf_kwargs):  # noqa: E301
        &#34;&#34;&#34;
        Sets gelf console logger. Handler for console output is not included by default,
        for testing in non-gelf environments use stdout=True.

        Args:
            log_level: logging level, default: &#39;logging.INFO&#39;
            transport_layer: &#39;TCP&#39; or &#39;UDP&#39;, default:&#39;UDP
            stdout: if set to True, Stout handler is also included
            include_extra_fields:
                Include extra GELF fields in the log messages.
                e.g. logging.warning(&#39;Some warning&#39;,
                                     extra={&#34;additional_info&#34;: &#34;Extra info to be displayed in the detail&#34;}

        Returns: Logger object
        &#34;&#34;&#34;
        # remove existing handlers
        for h in logging.getLogger().handlers:
            logging.getLogger().removeHandler(h)
        if stdout:
            CommonInterface.set_default_logger(log_level)

        # gelf handler setup
        gelf_kwargs[&#39;include_extra_fields&#39;] = include_extra_fields

        host = os.getenv(&#39;KBC_LOGGER_ADDR&#39;, &#39;localhost&#39;)
        port = os.getenv(&#39;KBC_LOGGER_PORT&#39;, 12201)
        if transport_layer == &#39;TCP&#39;:
            gelf = GelfTcpHandler(host=host, port=port, **gelf_kwargs)
        elif transport_layer == &#39;UDP&#39;:
            gelf = GelfUdpHandler(host=host, port=port, **gelf_kwargs)
        else:
            raise ValueError(F&#39;Unsupported gelf transport layer: {transport_layer}. Choose TCP or UDP&#39;)

        logging.getLogger().setLevel(log_level)
        logging.getLogger().addHandler(gelf)

        logger = logging.getLogger()
        return logger

    def get_state_file(self) -&gt; dict:
        &#34;&#34;&#34;

        Returns dict representation of state file or empty dict if not present

        Returns:
            dict:

        &#34;&#34;&#34;
        logging.info(&#39;Loading state file..&#39;)
        state_file_path = os.path.join(self.data_folder_path, &#39;in&#39;, &#39;state.json&#39;)
        if not os.path.isfile(state_file_path):
            logging.info(&#39;State file not found. First run?&#39;)
            return {}
        try:
            with open(state_file_path, &#39;r&#39;) \
                    as state_file:
                return json.load(state_file)
        except (OSError, IOError):
            raise ValueError(
                &#34;State file state.json unable to read &#34;
            )

    def write_state_file(self, state_dict: dict):
        &#34;&#34;&#34;
        Stores [state file](https://developers.keboola.com/extend/common-interface/config-file/#state-file).
        Args:
            state_dict (dict):
        &#34;&#34;&#34;
        if not isinstance(state_dict, dict):
            raise TypeError(&#39;Dictionary expected as a state file datatype!&#39;)

        with open(os.path.join(self.configuration.data_dir, &#39;out&#39;, &#39;state.json&#39;), &#39;w+&#39;) as state_file:
            json.dump(state_dict, state_file)

    def get_input_table_definition_by_name(self, table_name: str) -&gt; dao.TableDefinition:
        &#34;&#34;&#34;
        Return dao.TableDefinition object by table name.

        If nor the table itself or it&#39;s manifest exists, a ValueError is thrown.

        The dao.TableDefinition will contain full path of the source file, it&#39;s name and manifest (if present). It also
        provides methods for updating the manifest metadata.

        Args:
            table_name: Destination table name (name of .csv file). e.g. input.csv

        Returns:
            dao.TableDefinition
        &#34;&#34;&#34;
        manifest_path = os.path.join(
            self.tables_in_path,
            table_name + &#39;.manifest&#39;
        )

        return dao.TableDefinition.build_from_manifest(manifest_path)

    def get_input_tables_definitions(self, orphaned_manifests=False) -&gt; List[dao.TableDefinition]:
        &#34;&#34;&#34;
        Return dao.TableDefinition objects by scanning the `data/in/tables` folder.

        The dao.TableDefinition will contain full path of the source file, it&#39;s name and manifest (if present). It also
        provides methods for updating the manifest metadata.

        By default, orphaned manifests are skipped.


        See Also: keboola.component.dao.dao.TableDefinition

        Args:
            orphaned_manifests (bool): If True, manifests without corresponding files are fetched. This is useful in
            in scenarios where [workspaces exchange](
            https://developers.keboola.com/extend/common-interface/folders/#exchanging-data-via-workspace) is used
            e.g. when only manifest files are present in the `data/in/tables` folder.

        Returns: List[dao.TableDefinition]

        &#34;&#34;&#34;

        table_files = [f for f in glob.glob(self.tables_in_path + &#34;/**&#34;, recursive=False) if
                       not f.endswith(&#39;.manifest&#39;)]
        table_defs = list()
        for t in table_files:
            p = Path(t)
            manifest_path = t + &#39;.manifest&#39;

            if p.is_dir() and not Path(manifest_path).exists():
                # skip folders that do not have matching manifest
                logging.warning(f&#39;Folder {t} does not have matching manifest, it will be ignored!&#39;)
                continue

            table_defs.append(dao.TableDefinition.build_from_manifest(manifest_path))

        if orphaned_manifests:
            files_w_manifest = [t.name + &#39;.manifest&#39; for t in table_defs]
            manifest_files = [f for f in glob.glob(self.tables_in_path + &#34;/**.manifest&#34;, recursive=False)
                              if Path(f).name not in files_w_manifest]
            for t in manifest_files:
                p = Path(t)

                if p.is_dir():
                    # skip folders that do not have matching manifest
                    logging.warning(f&#39;Manifest {t} is folder,s skipping!&#39;)
                    continue

                table_defs.append(dao.TableDefinition.build_from_manifest(t))
        return table_defs

    def _create_table_definition(self, name: str,
                                 storage_stage: str = &#39;out&#39;,
                                 is_sliced: bool = False,
                                 destination: str = &#39;&#39;,
                                 primary_key: List[str] = None,
                                 columns: List[str] = None,
                                 incremental: bool = None,
                                 table_metadata: dao.TableMetadata = None,
                                 enclosure: str = &#39;&#34;&#39;,
                                 delimiter: str = &#39;,&#39;,
                                 delete_where: dict = None,
                                 write_always: bool = False,
                                 schema: Union[
                                     OrderedDict[str, ColumnDefinition], list[str]] = None,
                                 has_header: Optional[bool] = None) -&gt; dao.TableDefinition:
        &#34;&#34;&#34;
                Helper method for dao.TableDefinition creation along with the &#34;manifest&#34;.
                It initializes path according to the storage_stage type.

                Args:
                    name: Table / file name. e.g. `&#39;my_table.csv&#39;`.
                    storage_stage:
                        default value: &#39;out&#39;
                        either `&#39;in&#39;` or `&#39;out&#39;`. Determines the path to result file.
                        E.g. `data/tables/in/my_table.csv`
                    is_sliced: True if the full_path points to a folder with sliced tables
                    destination: String name of the table in Storage.
                    primary_key: List with names of columns used for primary key.
                    columns: List of columns for headless CSV files
                    incremental: Set to true to enable incremental loading
                    table_metadata: &lt;.dao.TableMetadata&gt; object containing column and table metadata
                    enclosure: str: CSV enclosure, by default &#34;
                    delimiter: str: CSV delimiter, by default ,
                    delete_where: Dict with settings for deleting rows
                    write_always: Bool: If true, the table will be saved to Storage even when the job execution
                           fails.
        &#34;&#34;&#34;
        if storage_stage == &#39;in&#39;:
            full_path = os.path.join(self.tables_in_path, name)
        elif storage_stage == &#39;out&#39;:
            full_path = os.path.join(self.tables_out_path, name)
        else:
            raise ValueError(f&#39;Invalid storage_stage value &#34;{storage_stage}&#34;. Supported values are: &#34;in&#34; or &#34;out&#34;!&#39;)

        # for transition period we need to force legacy mode for csv files w headers.
        force_legacy_mode = False
        if not schema and not columns and primary_key:
            warnings.warn(&#39;Primary key is set but columns are not. Forcing legacy mode for CSV file.&#39;,
                          DeprecationWarning)
            force_legacy_mode = True
        return dao.TableDefinition(name=name,
                                   full_path=full_path,
                                   is_sliced=is_sliced,
                                   destination=destination,
                                   primary_key=primary_key,
                                   columns=columns,
                                   incremental=incremental,
                                   table_metadata=table_metadata,
                                   enclosure=enclosure,
                                   delimiter=delimiter,
                                   delete_where=delete_where,
                                   stage=storage_stage,
                                   write_always=write_always,
                                   schema=schema,
                                   has_header=has_header,
                                   force_legacy_mode=force_legacy_mode)

    def create_in_table_definition(self, name: str,
                                   is_sliced: bool = False,
                                   destination: str = &#39;&#39;,
                                   primary_key: List[str] = None,
                                   columns: List[str] = None,
                                   incremental: bool = None,
                                   table_metadata: dao.TableMetadata = None,
                                   delete_where: str = None,
                                   schema: List[ColumnDefinition] = None) -&gt; dao.TableDefinition:
        &#34;&#34;&#34;
                       Helper method for input dao.TableDefinition creation along with the &#34;manifest&#34;.
                       It initializes path in data/tables/in/ folder.

                       Args:
                           name: Table / file name. e.g. `&#39;my_table.csv&#39;`.
                           is_sliced: True if the full_path points to a folder with sliced tables
                           destination: String name of the table in Storage.
                           primary_key: List with names of columns used for primary key.
                           columns: List of columns for headless CSV files
                           incremental: Set to true to enable incremental loading
                           table_metadata: &lt;.dao.TableMetadata&gt; object containing column and table metadata
                           delete_where: Dict with settings for deleting rows
                           schema: Table schema
        &#34;&#34;&#34;

        return self._create_table_definition(name=name,
                                             storage_stage=&#39;in&#39;,
                                             is_sliced=is_sliced,
                                             destination=destination,
                                             primary_key=primary_key,
                                             columns=columns,
                                             incremental=incremental,
                                             table_metadata=table_metadata,
                                             delete_where=delete_where,
                                             schema=schema)

    SCHEMA_TYPE = Union[Dict[str, ColumnDefinition], OrderedDict[str, ColumnDefinition], List[str]]

    def create_out_table_definition(self, name: str,
                                    is_sliced: bool = False,
                                    destination: str = &#39;&#39;,
                                    primary_key: List[str] = None,
                                    schema: SCHEMA_TYPE = None,
                                    incremental: bool = None,
                                    table_metadata: dao.TableMetadata = None,
                                    enclosure: str = &#39;&#34;&#39;,
                                    delimiter: str = &#39;,&#39;,
                                    delete_where: dict = None,
                                    write_always: bool = False,
                                    has_header: Optional[bool] = None,
                                    **kwargs
                                    ) -&gt; dao.TableDefinition:
        &#34;&#34;&#34;
                       Helper method for output dao.TableDefinition creation along with the &#34;manifest&#34;.
                       It initializes path in data/tables/out/ folder.

                       Args:
                           name: Table / file name. e.g. `&#39;my_table.csv&#39;`.
                           is_sliced: True if the full_path points to a folder with sliced tables
                           destination: String name of the table in Storage.
                           primary_key: List with names of columns used for primary key.
                           schema: List of columns or mapping of column names and ColumnDefinition objects.
                            if list of strings is provided, the columns will be created with default settings
                            (BaseType.string)
                           incremental: Set to true to enable incremental loading
                           table_metadata: &lt;.dao.TableMetadata&gt; object containing column and table metadata
                           enclosure: str: CSV enclosure, by default &#34;
                           delimiter: str: CSV delimiter, by default ,
                           delete_where: Dict with settings for deleting rows
                           write_always: Bool: If true, the table will be saved to Storage even when the job execution
                           fails.
                           has_header:Optional[bool] = flag whether the header is present in the file,
                                if None legacy method is used
        &#34;&#34;&#34;

        return self._create_table_definition(name=name,
                                             storage_stage=&#39;out&#39;,
                                             is_sliced=is_sliced,
                                             destination=destination,
                                             primary_key=primary_key,
                                             columns=kwargs.get(&#39;columns&#39;),
                                             incremental=incremental,
                                             table_metadata=table_metadata,
                                             enclosure=enclosure,
                                             delimiter=delimiter,
                                             delete_where=delete_where,
                                             write_always=write_always,
                                             schema=schema,
                                             has_header=has_header)

    # # File processing

    def get_input_file_definitions_grouped_by_tag_group(self, orphaned_manifests=False,
                                                        only_latest_files=True,
                                                        tags: List[str] = None,
                                                        include_system_tags=False) \
            -&gt; Dict[str, List[dao.FileDefinition]]:
        &#34;&#34;&#34;
        Convenience method returning lists of files in dictionary grouped by tag group.

        (tag group is string built from alphabetically ordered and concatenated tags, e.g. &#39;tag1;tag2&#39;

        Args:
            orphaned_manifests (bool): If True, manifests without corresponding files are fetched. Otherwise
                    a ValueError is raised.
            only_latest_files (bool): If True, only latest versions of each files are included.
            tags (List[str]): optional list of tags. If specified only files containing specified tags will be fetched.
            include_system_tags (bool): optional flag that will use system generated tags in groups as well.
                                   See FileDefinition.SYSTEM_TAG_PREFIXES

        Returns:
            Dict[str,List[dao.FileDefinition]] indexed by tag group =&gt; string built from alphabetically ordered
            and concatenated tags, e.g. `tag1;tag2`

        &#34;&#34;&#34;
        file_definitions = self.get_input_files_definitions(orphaned_manifests, only_latest_files, tags)
        return self.__group_file_defs_by_tag_group(file_definitions, include_system_tags=include_system_tags)

    def get_input_file_definitions_grouped_by_name(self, orphaned_manifests=False, only_latest_files=True,
                                                   tags: List[str] = None) -&gt; Dict[str, List[dao.FileDefinition]]:
        &#34;&#34;&#34;
        Convenience method returning lists of files in dictionary grouped by file name.

        Args:
            orphaned_manifests (bool): If True, manifests without corresponding files are fetched. Otherwise
                    a ValueError is raised.
            only_latest_files (bool): If True, only latest versions of each files are included.
            tags (List[str]): optional list of tags. If specified only files with matching tag group will be fetched.

        Returns:

        &#34;&#34;&#34;
        file_definitions = self.get_input_files_definitions(orphaned_manifests, only_latest_files, tags)
        return self.__group_files_by_name(file_definitions)

    def __group_file_defs_by_tag_group(self, file_definitions: List[dao.FileDefinition], include_system_tags=False) \
            -&gt; Dict[str, List[dao.FileDefinition]]:

        files_per_tag: dict = {}
        for f in file_definitions:

            tag_group_v1 = f.tags if include_system_tags else f.user_tags
            tag_group_v1.sort()
            tag_group_key = &#39;;&#39;.join(tag_group_v1)
            if not files_per_tag.get(tag_group_key):
                files_per_tag[tag_group_key] = []
            files_per_tag[tag_group_key].append(f)
        return files_per_tag

    def _filter_files(self, file_definitions: List[dao.FileDefinition], tags: List[str] = None,
                      only_latest: bool = True) -&gt; List[dao.FileDefinition]:

        filtered_files = file_definitions

        if only_latest:
            filtered_files = self.__filter_filedefs_by_latest(filtered_files)

        # filter by tags
        if tags:
            new_filtered = []
            filter_set = set(tags)
            for fd in filtered_files:
                tags_set = set(fd.tags)
                if filter_set.issubset(tags_set):
                    new_filtered.append(fd)
            filtered_files = new_filtered

        return filtered_files

    def __group_files_by_name(self, file_definitions: List[dao.FileDefinition]) -&gt; Dict[str, List[dao.FileDefinition]]:
        files_per_name: dict = {}
        for f in file_definitions:
            if not files_per_name.get(f.name):
                files_per_name[f.name] = []
            files_per_name[f.name].append(f)
        return files_per_name

    def __filter_filedefs_by_latest(self, file_definitions: List[dao.FileDefinition]) -&gt; List[dao.FileDefinition]:
        &#34;&#34;&#34;
        Get latest file (according to the timestamp) by each filename
        Args:
            file_definitions:

        Returns:

        &#34;&#34;&#34;
        filtered_files = list()
        files_per_name = self.__group_files_by_name(file_definitions)
        for group in files_per_name:
            max_file = None
            max_timestamp = utc.localize(datetime(1900, 5, 17))
            for f in files_per_name[group]:
                creation_date = f.created
                # if date not present ignore and add anyway
                if creation_date is None or creation_date &gt; max_timestamp:
                    max_timestamp = creation_date
                    max_file = f
            filtered_files.append(max_file)
        return filtered_files

    def get_input_files_definitions(self, orphaned_manifests=False,
                                    only_latest_files=True,
                                    tags: Optional[List[str]] = None) -&gt; List[dao.FileDefinition]:
        &#34;&#34;&#34;
        Return dao.FileDefinition objects by scanning the `data/in/files` folder.

        The dao.FileDefinition will contain full path of the source file, it&#39;s name and manifest.

        By default only latest versions of each file are included.

        By default, orphaned manifests are skipped, otherwise fails with ValueError.

        A filter may be specified to match only some tags. All files containing specified tags will be returned.


        See Also: keboola.component.dao.FileDefinition

        Args:
            orphaned_manifests (bool): If True, manifests without corresponding files are fetched. Otherwise
            a ValueError is raised.
            only_latest_files (bool): If True, only latest versions of each files are included.
            tags (List[str]): optional list of tags. If specified only files with matching tag group will be fetched.

        Returns: List[dao.TableDefinition]

        &#34;&#34;&#34;

        in_files = [f for f in glob.glob(self.files_in_path + &#34;/**&#34;, recursive=False) if
                    not f.endswith(&#39;.manifest&#39;)]
        file_defs = list()
        for t in in_files:
            manifest_path = t + &#39;.manifest&#39;

            file_defs.append(dao.FileDefinition.build_from_manifest(manifest_path))

        if orphaned_manifests:
            files_w_manifest = [t.full_path for t in file_defs]
            manifest_files = [f for f in glob.glob(self.tables_in_path + &#34;/**.manifest&#34;, recursive=False)
                              if Path(f).name not in files_w_manifest]
            for t in manifest_files:
                p = Path(t)

                if p.is_dir():
                    # skip folders that do not have matching manifest
                    logging.warning(f&#39;Manifest {t} is folder,s skipping!&#39;)
                    continue

                file_defs.append(dao.FileDefinition.build_from_manifest(t))

        return self._filter_files(file_defs, tags, only_latest_files)

    def _create_file_definition(self,
                                name: str,
                                storage_stage: str = &#39;out&#39;,
                                tags: List[str] = None,
                                is_public: bool = False,
                                is_permanent: bool = False,
                                is_encrypted: bool = False,
                                notify: bool = False) -&gt; dao.FileDefinition:
        &#34;&#34;&#34;
                Helper method for dao.FileDefinition creation along with the &#34;manifest&#34;.
                It initializes path according to the storage_stage type.

                Args:
                                name (str): Name of the file, e.g. file.jpg.
                                tags (list):
                                    List of tags that are assigned to this file
                                is_public: When true, the file URL will be permanent and publicly accessible.
                                is_permanent: Keeps a file forever. If false, the file will be deleted after default
                                period of time (e.g.
                                15 days)
                                is_encrypted: If true, the file content will be encrypted in the storage.
                                notify: Notifies project administrators that a file was uploaded.
        &#34;&#34;&#34;
        if storage_stage == &#39;in&#39;:
            full_path = os.path.join(self.files_in_path, name)
        elif storage_stage == &#39;out&#39;:
            full_path = os.path.join(self.files_out_path, name)
        else:
            raise ValueError(f&#39;Invalid storage_stage value &#34;{storage_stage}&#34;. Supported values are: &#34;in&#34; or &#34;out&#34;!&#39;)

        return dao.FileDefinition(
            full_path=full_path,
            tags=tags,
            is_public=is_public,
            is_permanent=is_permanent,
            is_encrypted=is_encrypted,
            notify=notify)

    def create_out_file_definition(self, name: str,
                                   tags: List[str] = None,
                                   is_public: bool = False,
                                   is_permanent: bool = False,
                                   is_encrypted: bool = False,
                                   notify: bool = False) -&gt; dao.FileDefinition:
        &#34;&#34;&#34;
                       Helper method for input dao.FileDefinition creation along with the &#34;manifest&#34;.
                       It initializes path in data/files/out/ folder.

                       Args:
                                name (str): Name of the file, e.g. file.jpg.
                                tags (list):
                                    List of tags that are assigned to this file
                                is_public: When true, the file URL will be permanent and publicly accessible.
                                is_permanent: Keeps a file forever. If false, the file will be deleted after default
                                period of time (e.g.
                                15 days)
                                is_encrypted: If true, the file content will be encrypted in the storage.
                                notify: Notifies project administrators that a file was uploaded.
        &#34;&#34;&#34;

        return self._create_file_definition(name=name,
                                            storage_stage=&#39;out&#39;,
                                            tags=tags,
                                            is_public=is_public,
                                            is_permanent=is_permanent,
                                            is_encrypted=is_encrypted,
                                            notify=notify)

    # TODO: refactor the validate config so it&#39;s more userfriendly
    &#34;&#34;&#34;
        - Support for nested params?
    &#34;&#34;&#34;

    def validate_configuration_parameters(self, mandatory_params=None):
        &#34;&#34;&#34;
                Validates config parameters based on provided mandatory parameters.
                All provided parameters must be present in config to pass.
                ex1.:
                par1 = &#39;par1&#39;
                par2 = &#39;par2&#39;
                mandatory_params = [par1, par2]
                Validation will fail when one of the above parameters is not found

                Two levels of nesting:
                Parameters can be grouped as arrays par3 = [groupPar1, groupPar2]
                =&gt; at least one of the pars has to be present
                ex2.
                par1 = &#39;par1&#39;
                par2 = &#39;par2&#39;
                par3 = &#39;par3&#39;
                groupPar1 = &#39;groupPar1&#39;
                groupPar2 = &#39;groupPar2&#39;
                group1 = [groupPar1, groupPar2]
                group3 = [par3, group1]
                mandatory_params = [par1, par2, group1]

                Folowing logical expression is evaluated:
                Par1 AND Par2 AND (groupPar1 OR groupPar2)

                ex3
                par1 = &#39;par1&#39;
                par2 = &#39;par2&#39;
                par3 = &#39;par3&#39;
                groupPar1 = &#39;groupPar1&#39;
                groupPar2 = &#39;groupPar2&#39;
                group1 = [groupPar1, groupPar2]
                group3 = [par3, group1]
                mandatory_params = [par1, par2, group3]

                Following logical expression is evaluated:
                par1 AND par2 AND (par3 OR (groupPar1 AND groupPar2))
                &#34;&#34;&#34;
        if not mandatory_params:
            mandatory_params = []
        return self._validate_parameters(self.configuration.parameters, mandatory_params, &#39;config parameters&#39;)

    def validate_image_parameters(self, mandatory_params):
        &#34;&#34;&#34;
                Validates image parameters based on provided mandatory parameters.
                All provided parameters must be present in config to pass.
                ex1.:
                par1 = &#39;par1&#39;
                par2 = &#39;par2&#39;
                mandatory_params = [par1, par2]
                Validation will fail when one of the above parameters is not found

                Two levels of nesting:
                Parameters can be grouped as arrays par3 = [groupPar1, groupPar2]
                =&gt; at least one of the pars has to be present
                ex2.
                par1 = &#39;par1&#39;
                par2 = &#39;par2&#39;
                par3 = &#39;par3&#39;
                groupPar1 = &#39;groupPar1&#39;
                groupPar2 = &#39;groupPar2&#39;
                group1 = [groupPar1, groupPar2]
                group3 = [par3, group1]
                mandatory_params = [par1, par2, group1]

                Folowing logical expression is evaluated:
                Par1 AND Par2 AND (groupPar1 OR groupPar2)

                ex3
                par1 = &#39;par1&#39;
                par2 = &#39;par2&#39;
                par3 = &#39;par3&#39;
                groupPar1 = &#39;groupPar1&#39;
                groupPar2 = &#39;groupPar2&#39;
                group1 = [groupPar1, groupPar2]
                group3 = [par3, group1]
                mandatory_params = [par1, par2, group3]

                Following logical expression is evaluated:
                par1 AND par2 AND (par3 OR (groupPar1 AND groupPar2))
                &#34;&#34;&#34;
        return self._validate_parameters(self.configuration.image_parameters,
                                         mandatory_params, &#39;image/stack parameters&#39;)

    def _validate_parameters(self, parameters, mandatory_params, _type):
        &#34;&#34;&#34;
        Validates provided parameters based on provided mandatory parameters.
        All provided parameters must be present in config to pass.
        ex1.:
        par1 = &#39;par1&#39;
        par2 = &#39;par2&#39;
        mandatory_params = [par1, par2]
        Validation will fail when one of the above parameters is not found

        Two levels of nesting:
        Parameters can be grouped as arrays par3 = [groupPar1, groupPar2] =&gt; at least one of the pars has to be
        present
        ex2.
        par1 = &#39;par1&#39;
        par2 = &#39;par2&#39;
        par3 = &#39;par3&#39;
        groupPar1 = &#39;groupPar1&#39;
        groupPar2 = &#39;groupPar2&#39;
        group1 = [groupPar1, groupPar2]
        group3 = [par3, group1]
        mandatory_params = [par1, par2, group1]

        Folowing logical expression is evaluated:
        Par1 AND Par2 AND (groupPar1 OR groupPar2)

        ex3
        par1 = &#39;par1&#39;
        par2 = &#39;par2&#39;
        par3 = &#39;par3&#39;
        groupPar1 = &#39;groupPar1&#39;
        groupPar2 = &#39;groupPar2&#39;
        group1 = [groupPar1, groupPar2]
        group3 = [par3, group1]
        mandatory_params = [par1, par2, group3]

        Following logical expression is evaluated:
        par1 AND par2 AND (par3 OR (groupPar1 AND groupPar2))

        Raises:
            UserException: on missing parameters
        &#34;&#34;&#34;
        missing_fields = []
        for par in mandatory_params:
            if isinstance(par, list):
                missing_fields.extend(self._validate_par_group(par, parameters))
            elif parameters.get(par) is None:
                missing_fields.append(par)

        if missing_fields:
            raise UserException(
                &#39;Missing mandatory {} fields: [{}] &#39;.format(_type, &#39;, &#39;.join(missing_fields)))

    def _validate_par_group(self, par_group, parameters):
        missing_fields = []
        is_present = False
        for par in par_group:
            if isinstance(par, list):
                missing_subset = self._get_par_missing_fields(par, parameters)
                missing_fields.extend(missing_subset)
                if not missing_subset:
                    is_present = True

            elif parameters.get(par):
                is_present = True
            else:
                missing_fields.append(par)
        if not is_present:
            return missing_fields
        else:
            return []

    def _get_par_missing_fields(self, mand_params, parameters):
        missing_fields = []
        for par in mand_params:
            if not parameters.get(par):
                missing_fields.append(par)
        return missing_fields

    # ### PROPERTIES
    @property
    def configuration(self):
        # try to load the configuration
        # raises ValueError

        return Configuration(self.data_folder_path)

    @property
    def tables_out_path(self):
        return os.path.join(self.data_folder_path, &#39;out&#39;, &#39;tables&#39;)

    @property
    def tables_in_path(self):
        return os.path.join(self.data_folder_path, &#39;in&#39;, &#39;tables&#39;)

    @property
    def files_out_path(self):
        return os.path.join(self.data_folder_path, &#39;out&#39;, &#39;files&#39;)

    @property
    def files_in_path(self):
        return os.path.join(self.data_folder_path, &#39;in&#39;, &#39;files&#39;)

    @property
    def is_legacy_queue(self) -&gt; bool:
        &#34;&#34;&#34;
        Check if the project is running on legacy queue (v1)
        Returns:

        &#34;&#34;&#34;
        features = self.environment_variables.project_features
        running_in_kbc = self.environment_variables.stack_id or False

        is_legacy_queue = True
        if not running_in_kbc or &#39;queuev2&#39; in features:
            is_legacy_queue = False
        return is_legacy_queue

    def write_manifest(self, io_definition: Union[dao.FileDefinition, dao.TableDefinition],
                       legacy_manifest: Optional[bool] = None):
        &#34;&#34;&#34;
        Write a table manifest from dao.IODefinition. Creates the appropriate manifest file in the proper location.


        ** Usage:**

        ```python
        from keboola.component import CommonInterface
        from keboola.component import dao

        ci = CommonInterface()

        # build table definition
        table_def = ci.create_out_table_definition(name=&#39;my_new_table&#39;, mytable.csv&#39;
                                , incremental = True
                                , table_metadata = tm
                                ))
        ci.write_manifest(table_def)

        # build file definition
        file_def = ci.create_out_file_definition(name=&#39;my_file.xml&#39;, tags=[&#39;tag&#39;, &#39;tag2&#39;])
        ci.write_manifest(file_def)
        ```

        Args:
            io_definition Union[dao.FileDefinition, dao.TableDefinition]: Initialized dao.IODefinition
             object containing manifest.

        Returns:

        &#34;&#34;&#34;

        if not legacy_manifest:

            legacy_manifest = self._expects_legacy_manifest()

        manifest = io_definition.get_manifest_dictionary(legacy_queue=self.is_legacy_queue,
                                                         legacy_manifest=legacy_manifest)
        # make dirs if not exist
        os.makedirs(os.path.dirname(io_definition.full_path), exist_ok=True)
        with open(io_definition.full_path + &#39;.manifest&#39;, &#39;w&#39;) as manifest_file:
            json.dump(manifest, manifest_file)

    def _expects_legacy_manifest(self) -&gt; bool:
        running_in_kbc = self.environment_variables.stack_id or False
        legacy_manifest = (running_in_kbc
                           and self.environment_variables.data_type_support not in (&#39;authoritative&#39;, &#39;hints&#39;))

        om_override = self.configuration.config_data.get(&#39;storage&#39;, {}).get(&#39;output&#39;, {}).get(&#39;data_type_support&#39;)
        if om_override:
            legacy_manifest = om_override not in (&#39;authoritative&#39;, &#39;hints&#39;)
        return legacy_manifest

    def write_manifests(self, io_definitions: List[Union[dao.FileDefinition, dao.TableDefinition]],
                        legacy_manifest: Optional[bool] = None):
        &#34;&#34;&#34;
        Process all table definition objects and create appropriate manifest files.
        Args:
            io_definitions:
            legacy_manifest: If True, creates a legacy manifest otherwise, uses the new format if available in project.

        Returns:

        &#34;&#34;&#34;
        for io_def in io_definitions:
            self.write_manifest(io_def, legacy_manifest=legacy_manifest)

    # ############# DEPRECATED METHODS, TODO: remove

    @deprecated(version=&#39;1.3.0&#39;, reason=&#34;You should use write_manifest function&#34;)
    def write_filedef_manifest(self, file_definition: dao.FileDefinition):
        &#34;&#34;&#34;
        Write a table manifest from dao.FileDefinition. Creates the appropriate manifest file in the proper location.


        ** Usage:**

        ```python
        from keboola.component import CommonInterface
        from keboola.component import dao

        ci = CommonInterface()

        # build table definition
        file_def = ci.create_out_file_definition(name=&#39;my_file.xml&#39;, tags=[&#39;tag&#39;, &#39;tag2&#39;])
        ci.write_filedef_manifest(file_def)
        ```

        Args:
            file_definition (dao.FileDefinition): Initialized dao.FileDefinition object containing manifest.

        Returns:

        &#34;&#34;&#34;
        self.write_manifest(file_definition)

    @deprecated(version=&#39;1.3.0&#39;, reason=&#34;You should use write_manifests function&#34;)
    def write_filedef_manifests(self, file_definitions: List[dao.FileDefinition]):
        &#34;&#34;&#34;
        Process all table definition objects and create appropriate manifest files.
        Args:
            file_definitions:

        Returns:

        &#34;&#34;&#34;
        self.write_manifests(file_definitions)

    @deprecated(version=&#39;1.3.0&#39;, reason=&#34;You should use write_manifest function&#34;)
    def write_tabledef_manifest(self, table_definition: dao.TableDefinition):
        &#34;&#34;&#34;
        Write a table manifest from dao.TableDefinition. Creates the appropriate manifest file in the proper location.


        ** Usage:**

        ```python
        from keboola.component import CommonInterface
        from keboola.component import dao

        ci = CommonInterface()
        tm = dao.TableMetadata()
        tm.add_table_description(&#34;My new table&#34;)

        # build table definition
        table_def = ci.create_out_table_definition(name=&#39;my_new_table&#39;, mytable.csv&#39;
                                , incremental = True
                                , table_metadata = tm
                                ))
        ci.write_tabledef_manifest(table_def)
        ```

        Args:
            table_definition (dao.TableDefinition): Initialized dao.TableDefinition object containing manifest.

        Returns:

        &#34;&#34;&#34;
        self.write_manifest(table_definition, legacy_manifest=True)

    @deprecated(version=&#39;1.3.0&#39;, reason=&#34;You should use write_manifests function&#34;)
    def write_tabledef_manifests(self, table_definitions: List[dao.TableDefinition]):
        &#34;&#34;&#34;
        Process all table definition objects and create appropriate manifest files.
        Args:
            table_definitions:

        Returns:

        &#34;&#34;&#34;
        self.write_manifests(table_definitions, legacy_manifest=True)</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="keboola.component.base.ComponentBase" href="base.html#keboola.component.base.ComponentBase">ComponentBase</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="keboola.component.interface.CommonInterface.LOGGING_TYPE_GELF"><code class="name">var <span class="ident">LOGGING_TYPE_GELF</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="keboola.component.interface.CommonInterface.LOGGING_TYPE_STD"><code class="name">var <span class="ident">LOGGING_TYPE_STD</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="keboola.component.interface.CommonInterface.SCHEMA_TYPE"><code class="name">var <span class="ident">SCHEMA_TYPE</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="keboola.component.interface.CommonInterface.set_default_logger"><code class="name flex">
<span>def <span class="ident">set_default_logger</span></span>(<span>log_level: int = 20)</span>
</code></dt>
<dd>
<div class="desc"><p>Sets default console logger.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>log_level</code></strong></dt>
<dd>logging level, default: 'logging.INFO'</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Logger object</p></div>
</dd>
<dt id="keboola.component.interface.CommonInterface.set_gelf_logger"><code class="name flex">
<span>def <span class="ident">set_gelf_logger</span></span>(<span>log_level: int = 20, transport_layer='TCP', stdout=False, include_extra_fields=True, **gelf_kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Sets gelf console logger. Handler for console output is not included by default,
for testing in non-gelf environments use stdout=True.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>log_level</code></strong></dt>
<dd>logging level, default: 'logging.INFO'</dd>
<dt><strong><code>transport_layer</code></strong></dt>
<dd>'TCP' or 'UDP', default:'UDP</dd>
<dt><strong><code>stdout</code></strong></dt>
<dd>if set to True, Stout handler is also included</dd>
</dl>
<p>include_extra_fields:
Include extra GELF fields in the log messages.
e.g. logging.warning('Some warning',
extra={"additional_info": "Extra info to be displayed in the detail"}
Returns: Logger object</p></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="keboola.component.interface.CommonInterface.configuration"><code class="name">prop <span class="ident">configuration</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def configuration(self):
    # try to load the configuration
    # raises ValueError

    return Configuration(self.data_folder_path)</code></pre>
</details>
</dd>
<dt id="keboola.component.interface.CommonInterface.files_in_path"><code class="name">prop <span class="ident">files_in_path</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def files_in_path(self):
    return os.path.join(self.data_folder_path, &#39;in&#39;, &#39;files&#39;)</code></pre>
</details>
</dd>
<dt id="keboola.component.interface.CommonInterface.files_out_path"><code class="name">prop <span class="ident">files_out_path</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def files_out_path(self):
    return os.path.join(self.data_folder_path, &#39;out&#39;, &#39;files&#39;)</code></pre>
</details>
</dd>
<dt id="keboola.component.interface.CommonInterface.is_legacy_queue"><code class="name">prop <span class="ident">is_legacy_queue</span> : bool</code></dt>
<dd>
<div class="desc"><p>Check if the project is running on legacy queue (v1)
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def is_legacy_queue(self) -&gt; bool:
    &#34;&#34;&#34;
    Check if the project is running on legacy queue (v1)
    Returns:

    &#34;&#34;&#34;
    features = self.environment_variables.project_features
    running_in_kbc = self.environment_variables.stack_id or False

    is_legacy_queue = True
    if not running_in_kbc or &#39;queuev2&#39; in features:
        is_legacy_queue = False
    return is_legacy_queue</code></pre>
</details>
</dd>
<dt id="keboola.component.interface.CommonInterface.tables_in_path"><code class="name">prop <span class="ident">tables_in_path</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def tables_in_path(self):
    return os.path.join(self.data_folder_path, &#39;in&#39;, &#39;tables&#39;)</code></pre>
</details>
</dd>
<dt id="keboola.component.interface.CommonInterface.tables_out_path"><code class="name">prop <span class="ident">tables_out_path</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def tables_out_path(self):
    return os.path.join(self.data_folder_path, &#39;out&#39;, &#39;tables&#39;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="keboola.component.interface.CommonInterface.create_in_table_definition"><code class="name flex">
<span>def <span class="ident">create_in_table_definition</span></span>(<span>self, name: str, is_sliced: bool = False, destination: str = '', primary_key: List[str] = None, columns: List[str] = None, incremental: bool = None, table_metadata: dao.TableMetadata = None, delete_where: str = None, schema: List[ColumnDefinition] = None) ‑> <a title="keboola.component.dao.TableDefinition" href="dao.html#keboola.component.dao.TableDefinition">TableDefinition</a></span>
</code></dt>
<dd>
<div class="desc"><p>Helper method for input dao.TableDefinition creation along with the "manifest".
It initializes path in data/tables/in/ folder.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong></dt>
<dd>Table / file name. e.g. <code>'my_table.csv'</code>.</dd>
<dt><strong><code>is_sliced</code></strong></dt>
<dd>True if the full_path points to a folder with sliced tables</dd>
<dt><strong><code>destination</code></strong></dt>
<dd>String name of the table in Storage.</dd>
<dt><strong><code>primary_key</code></strong></dt>
<dd>List with names of columns used for primary key.</dd>
<dt><strong><code>columns</code></strong></dt>
<dd>List of columns for headless CSV files</dd>
<dt><strong><code>incremental</code></strong></dt>
<dd>Set to true to enable incremental loading</dd>
<dt><strong><code>table_metadata</code></strong></dt>
<dd>&lt;.dao.TableMetadata&gt; object containing column and table metadata</dd>
<dt><strong><code>delete_where</code></strong></dt>
<dd>Dict with settings for deleting rows</dd>
<dt><strong><code>schema</code></strong></dt>
<dd>Table schema</dd>
</dl></div>
</dd>
<dt id="keboola.component.interface.CommonInterface.create_out_file_definition"><code class="name flex">
<span>def <span class="ident">create_out_file_definition</span></span>(<span>self, name: str, tags: List[str] = None, is_public: bool = False, is_permanent: bool = False, is_encrypted: bool = False, notify: bool = False) ‑> <a title="keboola.component.dao.FileDefinition" href="dao.html#keboola.component.dao.FileDefinition">FileDefinition</a></span>
</code></dt>
<dd>
<div class="desc"><p>Helper method for input dao.FileDefinition creation along with the "manifest".
It initializes path in data/files/out/ folder.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the file, e.g. file.jpg.</dd>
<dt>tags (list):</dt>
<dt>List of tags that are assigned to this file</dt>
<dt><strong><code>is_public</code></strong></dt>
<dd>When true, the file URL will be permanent and publicly accessible.</dd>
<dt><strong><code>is_permanent</code></strong></dt>
<dd>Keeps a file forever. If false, the file will be deleted after default</dd>
<dt>period of time (e.g.</dt>
<dt>15 days)</dt>
<dt><strong><code>is_encrypted</code></strong></dt>
<dd>If true, the file content will be encrypted in the storage.</dd>
<dt><strong><code>notify</code></strong></dt>
<dd>Notifies project administrators that a file was uploaded.</dd>
</dl></div>
</dd>
<dt id="keboola.component.interface.CommonInterface.create_out_table_definition"><code class="name flex">
<span>def <span class="ident">create_out_table_definition</span></span>(<span>self, name: str, is_sliced: bool = False, destination: str = '', primary_key: List[str] = None, schema: SCHEMA_TYPE = None, incremental: bool = None, table_metadata: dao.TableMetadata = None, enclosure: str = '"', delimiter: str = ',', delete_where: dict = None, write_always: bool = False, has_header: Optional[bool] = None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper method for output dao.TableDefinition creation along with the "manifest".
It initializes path in data/tables/out/ folder.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong></dt>
<dd>Table / file name. e.g. <code>'my_table.csv'</code>.</dd>
<dt><strong><code>is_sliced</code></strong></dt>
<dd>True if the full_path points to a folder with sliced tables</dd>
<dt><strong><code>destination</code></strong></dt>
<dd>String name of the table in Storage.</dd>
<dt><strong><code>primary_key</code></strong></dt>
<dd>List with names of columns used for primary key.</dd>
<dt><strong><code>schema</code></strong></dt>
<dd>List of columns or mapping of column names and ColumnDefinition objects.</dd>
<dt>if list of strings is provided, the columns will be created with default settings</dt>
<dt>(BaseType.string)</dt>
<dt><strong><code>incremental</code></strong></dt>
<dd>Set to true to enable incremental loading</dd>
<dt><strong><code>table_metadata</code></strong></dt>
<dd>&lt;.dao.TableMetadata&gt; object containing column and table metadata</dd>
<dt><strong><code>enclosure</code></strong></dt>
<dd>str: CSV enclosure, by default "</dd>
<dt><strong><code>delimiter</code></strong></dt>
<dd>str: CSV delimiter, by default ,</dd>
<dt><strong><code>delete_where</code></strong></dt>
<dd>Dict with settings for deleting rows</dd>
<dt><strong><code>write_always</code></strong></dt>
<dd>Bool: If true, the table will be saved to Storage even when the job execution</dd>
</dl>
<p>fails.
has_header:Optional[bool] = flag whether the header is present in the file,
if None legacy method is used</p></div>
</dd>
<dt id="keboola.component.interface.CommonInterface.get_input_file_definitions_grouped_by_name"><code class="name flex">
<span>def <span class="ident">get_input_file_definitions_grouped_by_name</span></span>(<span>self, orphaned_manifests=False, only_latest_files=True, tags: List[str] = None) ‑> Dict[str, List[<a title="keboola.component.dao.FileDefinition" href="dao.html#keboola.component.dao.FileDefinition">FileDefinition</a>]]</span>
</code></dt>
<dd>
<div class="desc"><p>Convenience method returning lists of files in dictionary grouped by file name.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>orphaned_manifests</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, manifests without corresponding files are fetched. Otherwise
a ValueError is raised.</dd>
<dt><strong><code>only_latest_files</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, only latest versions of each files are included.</dd>
<dt><strong><code>tags</code></strong> :&ensp;<code>List[str]</code></dt>
<dd>optional list of tags. If specified only files with matching tag group will be fetched.</dd>
</dl>
<p>Returns:</p></div>
</dd>
<dt id="keboola.component.interface.CommonInterface.get_input_file_definitions_grouped_by_tag_group"><code class="name flex">
<span>def <span class="ident">get_input_file_definitions_grouped_by_tag_group</span></span>(<span>self, orphaned_manifests=False, only_latest_files=True, tags: List[str] = None, include_system_tags=False) ‑> Dict[str, List[<a title="keboola.component.dao.FileDefinition" href="dao.html#keboola.component.dao.FileDefinition">FileDefinition</a>]]</span>
</code></dt>
<dd>
<div class="desc"><p>Convenience method returning lists of files in dictionary grouped by tag group.</p>
<p>(tag group is string built from alphabetically ordered and concatenated tags, e.g. 'tag1;tag2'</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>orphaned_manifests</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, manifests without corresponding files are fetched. Otherwise
a ValueError is raised.</dd>
<dt><strong><code>only_latest_files</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, only latest versions of each files are included.</dd>
<dt><strong><code>tags</code></strong> :&ensp;<code>List[str]</code></dt>
<dd>optional list of tags. If specified only files containing specified tags will be fetched.</dd>
<dt><strong><code>include_system_tags</code></strong> :&ensp;<code>bool</code></dt>
<dd>optional flag that will use system generated tags in groups as well.
See FileDefinition.SYSTEM_TAG_PREFIXES</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Dict[str,List[dao.FileDefinition]] indexed by tag group =&gt; string built from alphabetically ordered
and concatenated tags, e.g. <code>tag1;tag2</code></p></div>
</dd>
<dt id="keboola.component.interface.CommonInterface.get_input_files_definitions"><code class="name flex">
<span>def <span class="ident">get_input_files_definitions</span></span>(<span>self, orphaned_manifests=False, only_latest_files=True, tags: Optional[List[str]] = None) ‑> List[<a title="keboola.component.dao.FileDefinition" href="dao.html#keboola.component.dao.FileDefinition">FileDefinition</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Return dao.FileDefinition objects by scanning the <code>data/in/files</code> folder.</p>
<p>The dao.FileDefinition will contain full path of the source file, it's name and manifest.</p>
<p>By default only latest versions of each file are included.</p>
<p>By default, orphaned manifests are skipped, otherwise fails with ValueError.</p>
<p>A filter may be specified to match only some tags. All files containing specified tags will be returned.</p>
<p>See Also: keboola.component.dao.FileDefinition</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>orphaned_manifests</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, manifests without corresponding files are fetched. Otherwise</dd>
<dt>a ValueError is raised.</dt>
<dt><strong><code>only_latest_files</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, only latest versions of each files are included.</dd>
<dt><strong><code>tags</code></strong> :&ensp;<code>List[str]</code></dt>
<dd>optional list of tags. If specified only files with matching tag group will be fetched.</dd>
</dl>
<p>Returns: List[dao.TableDefinition]</p></div>
</dd>
<dt id="keboola.component.interface.CommonInterface.get_input_table_definition_by_name"><code class="name flex">
<span>def <span class="ident">get_input_table_definition_by_name</span></span>(<span>self, table_name: str) ‑> <a title="keboola.component.dao.TableDefinition" href="dao.html#keboola.component.dao.TableDefinition">TableDefinition</a></span>
</code></dt>
<dd>
<div class="desc"><p>Return dao.TableDefinition object by table name.</p>
<p>If nor the table itself or it's manifest exists, a ValueError is thrown.</p>
<p>The dao.TableDefinition will contain full path of the source file, it's name and manifest (if present). It also
provides methods for updating the manifest metadata.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>table_name</code></strong></dt>
<dd>Destination table name (name of .csv file). e.g. input.csv</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>dao.TableDefinition</p></div>
</dd>
<dt id="keboola.component.interface.CommonInterface.get_input_tables_definitions"><code class="name flex">
<span>def <span class="ident">get_input_tables_definitions</span></span>(<span>self, orphaned_manifests=False) ‑> List[<a title="keboola.component.dao.TableDefinition" href="dao.html#keboola.component.dao.TableDefinition">TableDefinition</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Return dao.TableDefinition objects by scanning the <code>data/in/tables</code> folder.</p>
<p>The dao.TableDefinition will contain full path of the source file, it's name and manifest (if present). It also
provides methods for updating the manifest metadata.</p>
<p>By default, orphaned manifests are skipped.</p>
<p>See Also: keboola.component.dao.dao.TableDefinition</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>orphaned_manifests</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, manifests without corresponding files are fetched. This is useful in</dd>
</dl>
<p>in scenarios where <a href="https://developers.keboola.com/extend/common-interface/folders/#exchanging-data-via-workspace">workspaces exchange</a> is used
e.g. when only manifest files are present in the <code>data/in/tables</code> folder.
Returns: List[dao.TableDefinition]</p></div>
</dd>
<dt id="keboola.component.interface.CommonInterface.get_state_file"><code class="name flex">
<span>def <span class="ident">get_state_file</span></span>(<span>self) ‑> dict</span>
</code></dt>
<dd>
<div class="desc"><p>Returns dict representation of state file or empty dict if not present</p>
<h2 id="returns">Returns</h2>
<p>dict:</p></div>
</dd>
<dt id="keboola.component.interface.CommonInterface.validate_configuration_parameters"><code class="name flex">
<span>def <span class="ident">validate_configuration_parameters</span></span>(<span>self, mandatory_params=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Validates config parameters based on provided mandatory parameters.
All provided parameters must be present in config to pass.
ex1.:
par1 = 'par1'
par2 = 'par2'
mandatory_params = [par1, par2]
Validation will fail when one of the above parameters is not found</p>
<p>Two levels of nesting:
Parameters can be grouped as arrays par3 = [groupPar1, groupPar2]
=&gt; at least one of the pars has to be present
ex2.
par1 = 'par1'
par2 = 'par2'
par3 = 'par3'
groupPar1 = 'groupPar1'
groupPar2 = 'groupPar2'
group1 = [groupPar1, groupPar2]
group3 = [par3, group1]
mandatory_params = [par1, par2, group1]</p>
<p>Folowing logical expression is evaluated:
Par1 AND Par2 AND (groupPar1 OR groupPar2)</p>
<p>ex3
par1 = 'par1'
par2 = 'par2'
par3 = 'par3'
groupPar1 = 'groupPar1'
groupPar2 = 'groupPar2'
group1 = [groupPar1, groupPar2]
group3 = [par3, group1]
mandatory_params = [par1, par2, group3]</p>
<p>Following logical expression is evaluated:
par1 AND par2 AND (par3 OR (groupPar1 AND groupPar2))</p></div>
</dd>
<dt id="keboola.component.interface.CommonInterface.validate_image_parameters"><code class="name flex">
<span>def <span class="ident">validate_image_parameters</span></span>(<span>self, mandatory_params)</span>
</code></dt>
<dd>
<div class="desc"><p>Validates image parameters based on provided mandatory parameters.
All provided parameters must be present in config to pass.
ex1.:
par1 = 'par1'
par2 = 'par2'
mandatory_params = [par1, par2]
Validation will fail when one of the above parameters is not found</p>
<p>Two levels of nesting:
Parameters can be grouped as arrays par3 = [groupPar1, groupPar2]
=&gt; at least one of the pars has to be present
ex2.
par1 = 'par1'
par2 = 'par2'
par3 = 'par3'
groupPar1 = 'groupPar1'
groupPar2 = 'groupPar2'
group1 = [groupPar1, groupPar2]
group3 = [par3, group1]
mandatory_params = [par1, par2, group1]</p>
<p>Folowing logical expression is evaluated:
Par1 AND Par2 AND (groupPar1 OR groupPar2)</p>
<p>ex3
par1 = 'par1'
par2 = 'par2'
par3 = 'par3'
groupPar1 = 'groupPar1'
groupPar2 = 'groupPar2'
group1 = [groupPar1, groupPar2]
group3 = [par3, group1]
mandatory_params = [par1, par2, group3]</p>
<p>Following logical expression is evaluated:
par1 AND par2 AND (par3 OR (groupPar1 AND groupPar2))</p></div>
</dd>
<dt id="keboola.component.interface.CommonInterface.write_filedef_manifest"><code class="name flex">
<span>def <span class="ident">write_filedef_manifest</span></span>(<span>self, file_definition: dao.FileDefinition)</span>
</code></dt>
<dd>
<div class="desc"><p>Write a table manifest from dao.FileDefinition. Creates the appropriate manifest file in the proper location.</p>
<p>** Usage:**</p>
<pre><code class="language-python">from keboola.component import CommonInterface
from keboola.component import dao

ci = CommonInterface()

# build table definition
file_def = ci.create_out_file_definition(name='my_file.xml', tags=['tag', 'tag2'])
ci.write_filedef_manifest(file_def)
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>file_definition</code></strong> :&ensp;<code>dao.FileDefinition</code></dt>
<dd>Initialized dao.FileDefinition object containing manifest.</dd>
</dl>
<p>Returns:</p></div>
</dd>
<dt id="keboola.component.interface.CommonInterface.write_filedef_manifests"><code class="name flex">
<span>def <span class="ident">write_filedef_manifests</span></span>(<span>self, file_definitions: List[dao.FileDefinition])</span>
</code></dt>
<dd>
<div class="desc"><p>Process all table definition objects and create appropriate manifest files.</p>
<h2 id="args">Args</h2>
<p>file_definitions:
Returns:</p></div>
</dd>
<dt id="keboola.component.interface.CommonInterface.write_manifest"><code class="name flex">
<span>def <span class="ident">write_manifest</span></span>(<span>self, io_definition: Union[dao.FileDefinition, dao.TableDefinition], legacy_manifest: Optional[bool] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Write a table manifest from dao.IODefinition. Creates the appropriate manifest file in the proper location.</p>
<p>** Usage:**</p>
<pre><code class="language-python">from keboola.component import CommonInterface
from keboola.component import dao

ci = CommonInterface()

# build table definition
table_def = ci.create_out_table_definition(name='my_new_table', mytable.csv'
                        , incremental = True
                        , table_metadata = tm
                        ))
ci.write_manifest(table_def)

# build file definition
file_def = ci.create_out_file_definition(name='my_file.xml', tags=['tag', 'tag2'])
ci.write_manifest(file_def)
</code></pre>
<h2 id="args">Args</h2>
<p>io_definition Union[dao.FileDefinition, dao.TableDefinition]: Initialized dao.IODefinition
object containing manifest.
Returns:</p></div>
</dd>
<dt id="keboola.component.interface.CommonInterface.write_manifests"><code class="name flex">
<span>def <span class="ident">write_manifests</span></span>(<span>self, io_definitions: List[Union[dao.FileDefinition, dao.TableDefinition]], legacy_manifest: Optional[bool] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Process all table definition objects and create appropriate manifest files.</p>
<h2 id="args">Args</h2>
<dl>
<dt>io_definitions:</dt>
<dt><strong><code>legacy_manifest</code></strong></dt>
<dd>If True, creates a legacy manifest otherwise, uses the new format if available in project.</dd>
</dl>
<p>Returns:</p></div>
</dd>
<dt id="keboola.component.interface.CommonInterface.write_state_file"><code class="name flex">
<span>def <span class="ident">write_state_file</span></span>(<span>self, state_dict: dict)</span>
</code></dt>
<dd>
<div class="desc"><p>Stores <a href="https://developers.keboola.com/extend/common-interface/config-file/#state-file">state file</a>.</p>
<h2 id="args">Args</h2>
<p>state_dict (dict):</p></div>
</dd>
<dt id="keboola.component.interface.CommonInterface.write_tabledef_manifest"><code class="name flex">
<span>def <span class="ident">write_tabledef_manifest</span></span>(<span>self, table_definition: dao.TableDefinition)</span>
</code></dt>
<dd>
<div class="desc"><p>Write a table manifest from dao.TableDefinition. Creates the appropriate manifest file in the proper location.</p>
<p>** Usage:**</p>
<pre><code class="language-python">from keboola.component import CommonInterface
from keboola.component import dao

ci = CommonInterface()
tm = dao.TableMetadata()
tm.add_table_description(&quot;My new table&quot;)

# build table definition
table_def = ci.create_out_table_definition(name='my_new_table', mytable.csv'
                        , incremental = True
                        , table_metadata = tm
                        ))
ci.write_tabledef_manifest(table_def)
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>table_definition</code></strong> :&ensp;<code>dao.TableDefinition</code></dt>
<dd>Initialized dao.TableDefinition object containing manifest.</dd>
</dl>
<p>Returns:</p></div>
</dd>
<dt id="keboola.component.interface.CommonInterface.write_tabledef_manifests"><code class="name flex">
<span>def <span class="ident">write_tabledef_manifests</span></span>(<span>self, table_definitions: List[dao.TableDefinition])</span>
</code></dt>
<dd>
<div class="desc"><p>Process all table definition objects and create appropriate manifest files.</p>
<h2 id="args">Args</h2>
<p>table_definitions:
Returns:</p></div>
</dd>
</dl>
</dd>
<dt id="keboola.component.interface.Configuration"><code class="flex name class">
<span>class <span class="ident">Configuration</span></span>
<span>(</span><span>data_folder_path: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Class representing configuration file generated and read
by KBC for docker applications
See docs:
<a href="https://developers.keboola.com/extend/common-interface/config-file/">https://developers.keboola.com/extend/common-interface/config-file/</a></p>
<h2 id="args">Args</h2>
<p>data_folder_path (object):</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Configuration:
    &#34;&#34;&#34;
    Class representing configuration file generated and read
    by KBC for docker applications
    See docs:
    https://developers.keboola.com/extend/common-interface/config-file/
    &#34;&#34;&#34;

    def __init__(self, data_folder_path: str):
        &#34;&#34;&#34;

        Args:
            data_folder_path (object):
        &#34;&#34;&#34;
        self.config_data = {}
        self.data_dir = data_folder_path

        try:
            with open(os.path.join(data_folder_path, &#39;config.json&#39;), &#39;r&#39;) \
                    as config_file:
                self.config_data = json.load(config_file)
        except (OSError, IOError):
            raise ValueError(
                f&#34;Configuration file config.json not found, verify that the data directory is correct and that the &#34;
                f&#34;config file is present. Dir: &#34;
                f&#34;{self.data_dir}&#34;
            )

        self.parameters = self.config_data.get(&#39;parameters&#39;, {})
        self.image_parameters = self.config_data.get(&#39;image_parameters&#39;, {})
        self.action = self.config_data.get(&#39;action&#39;, &#39;&#39;)
        self.workspace_credentials = self.config_data.get(&#39;authorization&#39;, {}).get(&#39;workspace&#39;, {})

    # ################ PROPERTIES
    @property
    def oauth_credentials(self) -&gt; dao.OauthCredentials:
        &#34;&#34;&#34;
        Returns subscriptable class OauthCredentials

        Returns: OauthCredentials

        &#34;&#34;&#34;
        oauth_credentials = self.config_data.get(&#39;authorization&#39;, {}).get(&#39;oauth_api&#39;, {}).get(&#39;credentials&#39;, {})
        credentials = None
        if oauth_credentials:
            credentials = dao.OauthCredentials(
                id=oauth_credentials.get(&#34;id&#34;, &#39;&#39;),
                created=oauth_credentials.get(&#34;created&#34;, &#39;&#39;),
                data=json.loads(oauth_credentials.get(&#34;#data&#34;, &#39;{}&#39;)),
                oauthVersion=oauth_credentials.get(&#34;oauthVersion&#34;, &#39;&#39;),
                appKey=oauth_credentials.get(&#34;appKey&#34;, &#39;&#39;),
                appSecret=oauth_credentials.get(&#34;#appSecret&#34;, &#39;&#39;)
            )
        return credentials

    @property
    def tables_input_mapping(self) -&gt; List[dao.TableInputMapping]:
        &#34;&#34;&#34;
        List of table [input mappings](https://developers.keboola.com/extend/common-interface/config-file/#tables)

        Tables specified in the configuration file.

        Returns: List[TableInputMapping]

        &#34;&#34;&#34;

        tables_defs = self.config_data.get(&#39;storage&#39;, {}).get(&#39;input&#39;, {}).get(&#39;tables&#39;, [])
        tables = []
        for table in tables_defs:
            # nested dataclass
            table[&#39;column_types&#39;] = [dao.build_dataclass_from_dict(dao.TableColumnTypes, coltype) for coltype in
                                     table.get(&#39;column_types&#39;, [])]

            im = dao.build_dataclass_from_dict(dao.TableInputMapping, table)
            im.full_path = os.path.normpath(
                os.path.join(
                    self.data_dir,
                    &#39;in&#39;,
                    &#39;tables&#39;,
                    table[&#39;destination&#39;]
                )
            )
            tables.append(im)
        return tables

    @property
    def tables_output_mapping(self) -&gt; List[dao.TableOutputMapping]:
        &#34;&#34;&#34;
        List of table [output mappings](https://developers.keboola.com/extend/common-interface/config-file/#tables)

        Get tables which are supposed to be returned when the application finishes. (from configuration[
        &#39;storage&#39;] section.
        Returns: List[TableOutputMapping]

        &#34;&#34;&#34;
        tables_defs = self.config_data.get(&#39;storage&#39;, {}).get(&#39;output&#39;, {}).get(&#39;tables&#39;, [])
        tables = []
        for table in tables_defs:
            om = dao.build_dataclass_from_dict(dao.TableOutputMapping, table)
            tables.append(om)
        return tables

    @property
    def files_input_mapping(self) -&gt; List[dao.FileInputMapping]:
        &#34;&#34;&#34;
        List of file [input mappings](https://developers.keboola.com/extend/common-interface/config-file/#files)

        Files specified in the configuration file (defined on component&#39;s input mapping). (from configuration[
        &#39;storage&#39;] section.
        Returns: List[FileInputMapping]

        &#34;&#34;&#34;
        defs = self.config_data.get(&#39;storage&#39;, {}).get(&#39;output&#39;, {}).get(&#39;files&#39;, [])
        files = []
        for file in defs:
            om = dao.build_dataclass_from_dict(dao.FileInputMapping, file)
            files.append(om)
        return files

    @property
    def files_output_mapping(self) -&gt; List[dao.FileOutputMapping]:
        &#34;&#34;&#34;
        List of file [output mappings](https://developers.keboola.com/extend/common-interface/config-file/#files)

        Get files which are supposed to be returned when the application finishes. (from configuration[
        &#39;storage&#39;] section.
        Returns:

        &#34;&#34;&#34;
        defs = self.config_data.get(&#39;storage&#39;, {}).get(&#39;output&#39;, {}).get(&#39;files&#39;, [])
        files = []
        for file in defs:
            om = dao.build_dataclass_from_dict(dao.FileOutputMapping, file)
            files.append(om)
        return files</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="keboola.component.interface.Configuration.files_input_mapping"><code class="name">prop <span class="ident">files_input_mapping</span> : List[dao.FileInputMapping]</code></dt>
<dd>
<div class="desc"><p>List of file <a href="https://developers.keboola.com/extend/common-interface/config-file/#files">input mappings</a></p>
<p>Files specified in the configuration file (defined on component's input mapping). (from configuration[
'storage'] section.
Returns: List[FileInputMapping]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def files_input_mapping(self) -&gt; List[dao.FileInputMapping]:
    &#34;&#34;&#34;
    List of file [input mappings](https://developers.keboola.com/extend/common-interface/config-file/#files)

    Files specified in the configuration file (defined on component&#39;s input mapping). (from configuration[
    &#39;storage&#39;] section.
    Returns: List[FileInputMapping]

    &#34;&#34;&#34;
    defs = self.config_data.get(&#39;storage&#39;, {}).get(&#39;output&#39;, {}).get(&#39;files&#39;, [])
    files = []
    for file in defs:
        om = dao.build_dataclass_from_dict(dao.FileInputMapping, file)
        files.append(om)
    return files</code></pre>
</details>
</dd>
<dt id="keboola.component.interface.Configuration.files_output_mapping"><code class="name">prop <span class="ident">files_output_mapping</span> : List[dao.FileOutputMapping]</code></dt>
<dd>
<div class="desc"><p>List of file <a href="https://developers.keboola.com/extend/common-interface/config-file/#files">output mappings</a></p>
<p>Get files which are supposed to be returned when the application finishes. (from configuration[
'storage'] section.
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def files_output_mapping(self) -&gt; List[dao.FileOutputMapping]:
    &#34;&#34;&#34;
    List of file [output mappings](https://developers.keboola.com/extend/common-interface/config-file/#files)

    Get files which are supposed to be returned when the application finishes. (from configuration[
    &#39;storage&#39;] section.
    Returns:

    &#34;&#34;&#34;
    defs = self.config_data.get(&#39;storage&#39;, {}).get(&#39;output&#39;, {}).get(&#39;files&#39;, [])
    files = []
    for file in defs:
        om = dao.build_dataclass_from_dict(dao.FileOutputMapping, file)
        files.append(om)
    return files</code></pre>
</details>
</dd>
<dt id="keboola.component.interface.Configuration.oauth_credentials"><code class="name">prop <span class="ident">oauth_credentials</span> : dao.OauthCredentials</code></dt>
<dd>
<div class="desc"><p>Returns subscriptable class OauthCredentials</p>
<p>Returns: OauthCredentials</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def oauth_credentials(self) -&gt; dao.OauthCredentials:
    &#34;&#34;&#34;
    Returns subscriptable class OauthCredentials

    Returns: OauthCredentials

    &#34;&#34;&#34;
    oauth_credentials = self.config_data.get(&#39;authorization&#39;, {}).get(&#39;oauth_api&#39;, {}).get(&#39;credentials&#39;, {})
    credentials = None
    if oauth_credentials:
        credentials = dao.OauthCredentials(
            id=oauth_credentials.get(&#34;id&#34;, &#39;&#39;),
            created=oauth_credentials.get(&#34;created&#34;, &#39;&#39;),
            data=json.loads(oauth_credentials.get(&#34;#data&#34;, &#39;{}&#39;)),
            oauthVersion=oauth_credentials.get(&#34;oauthVersion&#34;, &#39;&#39;),
            appKey=oauth_credentials.get(&#34;appKey&#34;, &#39;&#39;),
            appSecret=oauth_credentials.get(&#34;#appSecret&#34;, &#39;&#39;)
        )
    return credentials</code></pre>
</details>
</dd>
<dt id="keboola.component.interface.Configuration.tables_input_mapping"><code class="name">prop <span class="ident">tables_input_mapping</span> : List[dao.TableInputMapping]</code></dt>
<dd>
<div class="desc"><p>List of table <a href="https://developers.keboola.com/extend/common-interface/config-file/#tables">input mappings</a></p>
<p>Tables specified in the configuration file.</p>
<p>Returns: List[TableInputMapping]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def tables_input_mapping(self) -&gt; List[dao.TableInputMapping]:
    &#34;&#34;&#34;
    List of table [input mappings](https://developers.keboola.com/extend/common-interface/config-file/#tables)

    Tables specified in the configuration file.

    Returns: List[TableInputMapping]

    &#34;&#34;&#34;

    tables_defs = self.config_data.get(&#39;storage&#39;, {}).get(&#39;input&#39;, {}).get(&#39;tables&#39;, [])
    tables = []
    for table in tables_defs:
        # nested dataclass
        table[&#39;column_types&#39;] = [dao.build_dataclass_from_dict(dao.TableColumnTypes, coltype) for coltype in
                                 table.get(&#39;column_types&#39;, [])]

        im = dao.build_dataclass_from_dict(dao.TableInputMapping, table)
        im.full_path = os.path.normpath(
            os.path.join(
                self.data_dir,
                &#39;in&#39;,
                &#39;tables&#39;,
                table[&#39;destination&#39;]
            )
        )
        tables.append(im)
    return tables</code></pre>
</details>
</dd>
<dt id="keboola.component.interface.Configuration.tables_output_mapping"><code class="name">prop <span class="ident">tables_output_mapping</span> : List[dao.TableOutputMapping]</code></dt>
<dd>
<div class="desc"><p>List of table <a href="https://developers.keboola.com/extend/common-interface/config-file/#tables">output mappings</a></p>
<p>Get tables which are supposed to be returned when the application finishes. (from configuration[
'storage'] section.
Returns: List[TableOutputMapping]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def tables_output_mapping(self) -&gt; List[dao.TableOutputMapping]:
    &#34;&#34;&#34;
    List of table [output mappings](https://developers.keboola.com/extend/common-interface/config-file/#tables)

    Get tables which are supposed to be returned when the application finishes. (from configuration[
    &#39;storage&#39;] section.
    Returns: List[TableOutputMapping]

    &#34;&#34;&#34;
    tables_defs = self.config_data.get(&#39;storage&#39;, {}).get(&#39;output&#39;, {}).get(&#39;tables&#39;, [])
    tables = []
    for table in tables_defs:
        om = dao.build_dataclass_from_dict(dao.TableOutputMapping, table)
        tables.append(om)
    return tables</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="keboola.component" href="index.html">keboola.component</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="keboola.component.interface.init_environment_variables" href="#keboola.component.interface.init_environment_variables">init_environment_variables</a></code></li>
<li><code><a title="keboola.component.interface.register_csv_dialect" href="#keboola.component.interface.register_csv_dialect">register_csv_dialect</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="keboola.component.interface.CommonInterface" href="#keboola.component.interface.CommonInterface">CommonInterface</a></code></h4>
<ul class="">
<li><code><a title="keboola.component.interface.CommonInterface.LOGGING_TYPE_GELF" href="#keboola.component.interface.CommonInterface.LOGGING_TYPE_GELF">LOGGING_TYPE_GELF</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.LOGGING_TYPE_STD" href="#keboola.component.interface.CommonInterface.LOGGING_TYPE_STD">LOGGING_TYPE_STD</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.SCHEMA_TYPE" href="#keboola.component.interface.CommonInterface.SCHEMA_TYPE">SCHEMA_TYPE</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.configuration" href="#keboola.component.interface.CommonInterface.configuration">configuration</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.create_in_table_definition" href="#keboola.component.interface.CommonInterface.create_in_table_definition">create_in_table_definition</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.create_out_file_definition" href="#keboola.component.interface.CommonInterface.create_out_file_definition">create_out_file_definition</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.create_out_table_definition" href="#keboola.component.interface.CommonInterface.create_out_table_definition">create_out_table_definition</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.files_in_path" href="#keboola.component.interface.CommonInterface.files_in_path">files_in_path</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.files_out_path" href="#keboola.component.interface.CommonInterface.files_out_path">files_out_path</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.get_input_file_definitions_grouped_by_name" href="#keboola.component.interface.CommonInterface.get_input_file_definitions_grouped_by_name">get_input_file_definitions_grouped_by_name</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.get_input_file_definitions_grouped_by_tag_group" href="#keboola.component.interface.CommonInterface.get_input_file_definitions_grouped_by_tag_group">get_input_file_definitions_grouped_by_tag_group</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.get_input_files_definitions" href="#keboola.component.interface.CommonInterface.get_input_files_definitions">get_input_files_definitions</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.get_input_table_definition_by_name" href="#keboola.component.interface.CommonInterface.get_input_table_definition_by_name">get_input_table_definition_by_name</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.get_input_tables_definitions" href="#keboola.component.interface.CommonInterface.get_input_tables_definitions">get_input_tables_definitions</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.get_state_file" href="#keboola.component.interface.CommonInterface.get_state_file">get_state_file</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.is_legacy_queue" href="#keboola.component.interface.CommonInterface.is_legacy_queue">is_legacy_queue</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.set_default_logger" href="#keboola.component.interface.CommonInterface.set_default_logger">set_default_logger</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.set_gelf_logger" href="#keboola.component.interface.CommonInterface.set_gelf_logger">set_gelf_logger</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.tables_in_path" href="#keboola.component.interface.CommonInterface.tables_in_path">tables_in_path</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.tables_out_path" href="#keboola.component.interface.CommonInterface.tables_out_path">tables_out_path</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.validate_configuration_parameters" href="#keboola.component.interface.CommonInterface.validate_configuration_parameters">validate_configuration_parameters</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.validate_image_parameters" href="#keboola.component.interface.CommonInterface.validate_image_parameters">validate_image_parameters</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.write_filedef_manifest" href="#keboola.component.interface.CommonInterface.write_filedef_manifest">write_filedef_manifest</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.write_filedef_manifests" href="#keboola.component.interface.CommonInterface.write_filedef_manifests">write_filedef_manifests</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.write_manifest" href="#keboola.component.interface.CommonInterface.write_manifest">write_manifest</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.write_manifests" href="#keboola.component.interface.CommonInterface.write_manifests">write_manifests</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.write_state_file" href="#keboola.component.interface.CommonInterface.write_state_file">write_state_file</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.write_tabledef_manifest" href="#keboola.component.interface.CommonInterface.write_tabledef_manifest">write_tabledef_manifest</a></code></li>
<li><code><a title="keboola.component.interface.CommonInterface.write_tabledef_manifests" href="#keboola.component.interface.CommonInterface.write_tabledef_manifests">write_tabledef_manifests</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="keboola.component.interface.Configuration" href="#keboola.component.interface.Configuration">Configuration</a></code></h4>
<ul class="">
<li><code><a title="keboola.component.interface.Configuration.files_input_mapping" href="#keboola.component.interface.Configuration.files_input_mapping">files_input_mapping</a></code></li>
<li><code><a title="keboola.component.interface.Configuration.files_output_mapping" href="#keboola.component.interface.Configuration.files_output_mapping">files_output_mapping</a></code></li>
<li><code><a title="keboola.component.interface.Configuration.oauth_credentials" href="#keboola.component.interface.Configuration.oauth_credentials">oauth_credentials</a></code></li>
<li><code><a title="keboola.component.interface.Configuration.tables_input_mapping" href="#keboola.component.interface.Configuration.tables_input_mapping">tables_input_mapping</a></code></li>
<li><code><a title="keboola.component.interface.Configuration.tables_output_mapping" href="#keboola.component.interface.Configuration.tables_output_mapping">tables_output_mapping</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.1</a>.</p>
</footer>
</body>
</html>
